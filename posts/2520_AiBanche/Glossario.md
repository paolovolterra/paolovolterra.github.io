# Glossario


## AI Act

- **Obiettivo**: Regolare l'uso dell'intelligenza artificiale nell'UE per proteggere i diritti fondamentali.
- **Categorie di Rischio**: Classifica le applicazioni AI in base al loro livello di rischio; quelle ad alto rischio, come le valutazioni del merito creditizio, sono soggette a controlli più rigorosi

## Allucinazione

In ambito AI, il termine **"allucinazione"** si riferisce a quando un modello di Intelligenza Artificiale **genera informazioni errate, inventate o fuorvianti**, pur presentandole come se fossero vere. Questo fenomeno è particolarmente rilevante nell'AI generativa (**GenAI**), come nei chatbot basati su modelli di linguaggio (LLM), ma può avvenire anche in sistemi di machine learning in altri ambiti.
Le allucinazioni avvengono perché i modelli di AI **non comprendono realmente il significato dei dati**, ma si basano su pattern statistici. 
Ecco alcune cause principali:
✅ **Mancanza di dati** – Se un modello non ha dati sufficienti su un argomento, può riempire i vuoti con informazioni errate.  
✅ **Bias nei dati di training** – Se i dati con cui è stato addestrato contengono errori o distorsioni, l’AI può replicarli.  
✅ **Modello predittivo, non verificativo** – L'AI genera risposte sulla base di probabilità statistiche, non su un controllo fattuale.  
✅ **Errori di contestualizzazione** – Può mescolare informazioni da fonti diverse, creando affermazioni incoerenti o inesatte.
Esempi:
- Un chatbot bancario potrebbe **inventare politiche sui prestiti** o riferire condizioni errate sui conti correnti.  
- Un modello di AI per il trading potrebbe suggerire decisioni basate su dati inesistenti o correlazioni errate.

## Deep Fake

contenuti multimediali (video, immagini, audio) **generati o manipolati con l'Intelligenza Artificiale** per creare simulazioni realistiche di persone, spesso con lo scopo di **ingannare o intrattenere**.
Questa tecnologia utilizza **reti neurali profonde** (da cui il nome _deep_ fake) per sostituire volti, voci o movimenti con grande precisione.

## DORA (Digital Operational Resilience Act)

- **Obiettivo**: Migliorare la resilienza operativa digitale delle istituzioni finanziarie, inclusi i servizi bancari.
- **Requisiti**: Le banche devono implementare misure per garantire la continuità operativa e gestire i rischi legati alla tecnologia.
- **Applicazione**: Si concentra su aspetti come la sicurezza informatica, l'efficienza dei processi digitali e la gestione degli incidenti.

## NIS2 (Network and Information Security Directive)

- **Obiettivo**: Rafforzare la sicurezza informatica delle entità essenziali e importanti nell'UE.
- **Requisiti Principali**:
    - Valutazione del rischio
    - Misure di sicurezza
    - Segnalazione degli incidenti
    - Sicurezza della catena di approvvigionamento
    - Formazione sulla cybersecurity
