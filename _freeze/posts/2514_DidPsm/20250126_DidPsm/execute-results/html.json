{
  "hash": "e72cc9ee1a3f0a9095be7331dd9a3b08",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Difference-in-Differences e Propensity Score Matching\"\nsubtitle: \"_due tecniche comuni di analisi causale_ \"\nauthor: \"Paolo Volterra\"\ndate: 2025-01-26\ncreated: 2025-01-12\nupdated: 2025-01-12\nlang: it\ndraft: false                # Pubblica il documento\njupyter: \"python3\"          # Specifica il kernel Python\nexecute:\n  freeze: true              # Congela l'esecuzione degli script\ntags: [statistica, Python]\n\nformat:\n  html:\n    toc: true               # Abilita il sommario\n    toc-depth: 3            # Mostra fino al terzo livello di intestazioni\n    number-sections: true   # Aggiunge numeri alle sezioni e sottosezioni\n    toc-location: right     # Posiziona il sommario a destra\n    toc-title: \"Indice\"     # Titolo del sommario\n\ncategories:\n  - Statistica\n  - Python\n\nimage: \"./media/DidPsm.png\"\n\n# ./posts/2514_DidPsm/20250126_DidPsm.qmd\n---\n\n\n\n\nIl Difference-in-Differences (DiD) e il Propensity Score Matching (PSM) sono due tecniche comuni di analisi causale. \n\nPuoi combinarle o usarle separatamente per stimare gli effetti di un trattamento.\n\n#DiD e #PSM sono frequentemente utilizzate negli studi sulle imprese per valutare gli effetti causali di interventi o politiche. \n\nQueste tecniche sono  applicate per isolare l'impatto di specifiche iniziative.\n\n\n## Difference-in-Differences (DiD)\nIl DiD confronta l'andamento dei risultati tra un gruppo trattato e un gruppo di controllo prima e dopo un evento/treatment. I passi principali sono:\n\n- Dividi i dati in gruppi trattati e di controllo.\n- Calcola le differenze nei risultati prima e dopo il trattamento per entrambi i gruppi.\n- La differenza di queste differenze rappresenta l'effetto del trattamento.\n\n## Esempio in Python\nSupponiamo di avere un dataset con le colonne group (trattato/controllo), time (pre/post), e outcome.\n\n::: {#53abd9ad .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# Dataset simulato\ndata = pd.DataFrame({\n    'group': [0, 0, 0, 1, 1, 1, 0, 0, 1, 1],\n    'time': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1],\n    'outcome': [5, 7, 6, 12, 5, 15, 6, 8, 5, 14]\n})\n\n# Aggiunta interazione trattato-tempo\ndata['group_time'] = data['group'] * data['time']\n\n# Regressione DiD\nmodel = smf.ols('outcome ~ group + time + group_time', data=data).fit()\nprint(model.summary())\n\n# Effetto del trattamento\ntreatment_effect = model.params['group_time']\nprint(f\"Effetto stimato del trattamento: {treatment_effect}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                outcome   R-squared:                       0.957\nModel:                            OLS   Adj. R-squared:                  0.936\nMethod:                 Least Squares   F-statistic:                     44.66\nDate:                Sun, 02 Feb 2025   Prob (F-statistic):           0.000169\nTime:                        19:58:20   Log-Likelihood:                -11.494\nNo. Observations:                  10   AIC:                             30.99\nDf Residuals:                       6   BIC:                             32.20\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      5.6667      0.569      9.954      0.000       4.274       7.060\ngroup         -0.6667      0.900     -0.741      0.487      -2.869       1.536\ntime           1.8333      0.900      2.037      0.088      -0.369       4.036\ngroup_time     6.8333      1.273      5.368      0.002       3.719       9.948\n==============================================================================\nOmnibus:                        2.318   Durbin-Watson:                   1.829\nProb(Omnibus):                  0.314   Jarque-Bera (JB):                0.540\nSkew:                          -0.549   Prob(JB):                        0.763\nKurtosis:                       3.302   Cond. No.                         7.01\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nEffetto stimato del trattamento: 6.833333333333329\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\paolo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:418: UserWarning:\n\n`kurtosistest` p-value may be inaccurate with fewer than 20 observations; only n=10 observations were given.\n\n```\n:::\n:::\n\n\n## Propensity Score Matching (PSM)\nIl PSM abbina le unità trattate con quelle di controllo che hanno una probabilità simile di ricevere il trattamento, basata su variabili osservabili. È utile per ridurre il bias di selezione.\n\nEsempio in Python\nSupponiamo di avere un dataset con le colonne treatment, outcome, e alcune variabili predittive (X1, X2).\n\n::: {#6185cd62 .cell execution_count=2}\n``` {.python .cell-code}\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import NearestNeighbors\n\n# Dataset simulato\ndata = pd.DataFrame({\n    'treatment': [1, 0, 1, 0, 1, 0, 1, 0],\n    'outcome': [10, 5, 12, 6, 11, 4, 13, 7],\n    'X1': [3, 2, 4, 2, 3, 1, 5, 2],\n    'X2': [7, 6, 8, 5, 7, 4, 9, 5]\n})\n\n# Calcolo del propensity score\nX = data[['X1', 'X2']]\ny = data['treatment']\nlogit = LogisticRegression()\ndata['propensity_score'] = logit.fit(X, y).predict_proba(X)[:, 1]\n\n# Matching usando i Nearest Neighbors\ntreated = data[data['treatment'] == 1]\ncontrol = data[data['treatment'] == 0]\nnn = NearestNeighbors(n_neighbors=1)\nnn.fit(control[['propensity_score']])\ndistances, indices = nn.kneighbors(treated[['propensity_score']])\n\n# Creazione del dataset abbinato\nmatched_control = control.iloc[indices.flatten()].reset_index(drop=True)\nmatched_treated = treated.reset_index(drop=True)\n\n# Unire i dati con suffissi\nmatched_data = pd.concat([matched_treated, matched_control], axis=1, keys=[\"treated\", \"control\"])\nmatched_data.columns = [f\"{col[0]}_{col[1]}\" for col in matched_data.columns]\n\n# Calcolo della differenza negli outcome\neffect = matched_data['treated_outcome'].mean() - matched_data['control_outcome'].mean()\nprint(f\"Effetto stimato del trattamento: {effect}\")\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEffetto stimato del trattamento: 6.5\n```\n:::\n:::\n\n\n## cosa significa 6.5?\n\nQuando il codice restituisce un valore come Effetto stimato del trattamento: 6.5, significa che l'effetto medio del trattamento (cioè la differenza media tra il gruppo trattato e il gruppo di controllo in termini di un determinato outcome) è pari a 6.5 unità\n\nIn termini pratici:\n\nIl gruppo trattato ha ricevuto un trattamento o intervento specifico.\nIl gruppo di controllo non ha ricevuto il trattamento, ma viene utilizzato come punto di riferimento per capire cosa sarebbe successo al gruppo trattato in assenza del trattamento.\n6.5 indica che, in media:\n\nIl trattamento ha aumentato (o ridotto) l'outcome del gruppo trattato di 6.5 unità rispetto al gruppo di controllo.\nUn esempio pratico\nSupponiamo che tu stia valutando l'effetto di un programma di formazione aziendale sulla produttività dei dipendenti, e l'outcome misurato sia il numero di unità prodotte.\n\nIl gruppo trattato (dipendenti che hanno partecipato al corso) ha una produttività media di 15 unità.\nIl gruppo di controllo (dipendenti che non hanno partecipato) ha una produttività media di 8.5 unità.\nL'effetto stimato del trattamento è: \n\n15−8.5=6.5\n\nL'intervento ha aumentato la produttività di 6.5 unità, in media.\n\n##Limiti e considerazioni\n- Causalità: L'effetto stimato assume che tutti i bias di selezione e le - differenze osservabili/non osservabili tra i due gruppi siano correttamente - gestiti (ad esempio, con il Propensity Score Matching o un disegno - sperimentale ben fatto).\n- Significatività statistica: È importante verificare se l'effetto stimato è - statisticamente significativo (es. con un test statistico).\n- Unità di misura: Assicurati che il risultato sia chiaro in termini dell'outcome misurato (es. unità prodotte, reddito, vendite, ecc.).\n\n\n## Librerie utili:\n\n- statsmodels: Per la regressione del DiD.\n- sklearn: Per calcolare il propensity score e abbinare i dati.\n- causalinference: Per analisi causali.\n- econml: Per metodi avanzati di stima degli effetti causali.\n\n",
    "supporting": [
      "20250126_DidPsm_files"
    ],
    "filters": [],
    "includes": {}
  }
}